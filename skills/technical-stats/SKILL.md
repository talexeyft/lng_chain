---
name: technical-stats
description: Описывает техническую статистику сети и работу с ней — SQLite-база ai_data/network_stats.db, таблица network_stats, read-only SQL. Использовать при запросах пользователя о статистике сети, KPI, метриках, отчётах по NE, трафике, качестве, eDRX, дропах, задержках, нагрузке.
allowed-tools: query_stats_db, execute_analysis_script, list_experiment_artifacts
---

# Техническая статистика сети

## Назначение

В проекте хранится **техническая статистика сети** в локальной SQLite-базе. Данные используются для анализа нагрузки, качества и KPI по сетевым элементам (NE) и датам. Доступ — **только чтение** (SELECT).

## Расположение и доступ

| Что | Где |
|-----|-----|
| База | `ai_data/network_stats.db` (от корня проекта) |
| Инструмент агента | `query_stats_db(sql, max_rows=500, save_to_file=False)` — только SELECT. По умолчанию возвращает таблицу в ответе; при `save_to_file=True` сохраняет результат в `ai_data/query_<id>.tsv` и возвращает путь и сводку (строки, колонки), не загружая полный дамп в контекст |
| Модуль | `tools/stats_db.run_stats_query()` |

Ограничения: разрешены **только SELECT**-запросы; результат ограничен `max_rows` (по умолчанию 500).

## Схема таблицы `network_stats`

**Ключ:** `(dt, ne)` — дата и идентификатор сетевого элемента.

| Колонка | Тип | Описание |
|---------|-----|----------|
| `dt` | DATE | Дата (YYYY-MM-DD) |
| `ne` | TEXT | Код NE (например bs-01, bs-02) |
| `calls` | INTEGER | Количество вызовов |
| `traffic_cs` | REAL | Трафик CS |
| `traffic_ps` | REAL | Трафик PS |
| `pct_edrx` | REAL | Доля eDRX, % |
| `drop_rate` | REAL | Доля дропов, % |
| `latency_ms` | REAL | Задержка, мс |
| `conn_attempts` | INTEGER | Попытки установления соединения |
| `handover_cnt` | INTEGER | Количество хэндоверов |
| `paging_succ` | REAL | Успешность пейджинга, % |
| `rrc_conn` | INTEGER | RRC-соединения |
| `dl_mbps` | REAL | Скорость downlink, Мбит/с |
| `ul_mbps` | REAL | Скорость uplink, Мбит/с |
| `prb_util` | REAL | Утилизация PRB, % |
| `cell_load` | REAL | Нагрузка соты, % |
| `paging_vol` | INTEGER | Объём пейджинга |

## Принципы работы

1. **Только чтение** — INSERT/UPDATE/DELETE через `query_stats_db` запрещены; агент не должен пытаться менять данные.
2. **Формулировка запросов** — писать валидный SQL (SELECT ... FROM network_stats [WHERE ...] [GROUP BY ...] [ORDER BY ...] [LIMIT ...]). Для больших выборок учитывать `max_rows` или явно задавать LIMIT. Для объёмных результатов использовать `save_to_file=True`, чтобы не раздувать контекст — данные сохранятся в файл, в ответ придёт путь и сводка.
3. **Агрегаты и фильтры** — для отчётов по периодам использовать `GROUP BY dt` или диапазон дат в WHERE; по NE — `GROUP BY ne` или фильтр по `ne`.
4. **Интерпретация** — при ответах пользователю переводить результат в понятный текст/выводы; при необходимости округлять числа и указывать единицы (%, Мбит/с, мс).

## Типовые сценарии

- Сводка по датам: `SELECT dt, SUM(calls), AVG(drop_rate), ... FROM network_stats GROUP BY dt ORDER BY dt`
- Топ NE по метрике: `SELECT ne, SUM(calls) AS total_calls FROM network_stats WHERE dt BETWEEN '...' AND '...' GROUP BY ne ORDER BY total_calls DESC LIMIT 20`
- Качество (дропы, задержка): фильтровать по `drop_rate`, `latency_ms`, `paging_succ`
- Нагрузка и трафик: `traffic_ps`, `traffic_cs`, `dl_mbps`, `ul_mbps`, `prb_util`, `cell_load`

## RCA низкого трафика (методология)

При анализе «почему у БС низкий трафик» используй единую методологию.

### Стандартные KPI для RCA

| Группа | Колонки | Назначение |
|--------|---------|------------|
| Трафик/спрос | `traffic_ps`, `traffic_cs`, `calls`, `rrc_conn` | Объём и активность |
| Качество | `drop_rate`, `latency_ms`, `paging_succ` | Дропы, задержка, пейджинг |
| Нагрузка/ёмкость | `prb_util`, `cell_load`, `dl_mbps`, `ul_mbps` | Перегрузка или недогрузка |
| Мобильность | `handover_cnt` | Хэндоверы |

### Окна времени

- **baseline** — исторический период (например, от (max_date − 90 дней) до (max_date − 15 дней)): «норма» для БС.
- **recent** — последние N дней (например, 14): текущее состояние.

Сравнивай медианы (или средние) по `baseline` и `recent` для каждой БС.

### Классификация статуса БС

- **всегда низкий** — baseline уже низкий (например, ниже 10% перцентиля по трафику), recent примерно такой же; причина — изначально низкий спрос или малая зона.
- **стал низкий** — baseline в норме, recent заметно ниже (например, падение >30%); искать причину просадки.
- **аномалия / недостаточно данных** — мало точек, пропуски по датам или противоречивые метрики; в отчёте указывать «требует ручной проверки».

### Порядок проверки причин (RCA)

Проверяй гипотезы в фиксированном порядке и подкрепляй цифрами:

1. **Доступность** — нет ли провалов по датам, нулевой трафик при нулевых вызовах (техсбой).
2. **Качество** — рост `drop_rate`, падение `paging_succ`, рост `latency_ms` в recent vs baseline.
3. **Спрос** — падение `calls`, `rrc_conn` при сохранном качестве (смещение трафика, отток абонентов).
4. **Нагрузка** — аномалии `prb_util`, `cell_load` (перегрузка или, наоборот, недогрузка после изменений).
5. **Сезонность/внешние факторы** — сравнение с тем же периодом год назад или с соседними БС.

### Confidence (уверенность в причине)

Для каждой названной причины указывай **confidence** от 0 до 1:

- **0.8–1.0** — причина явно подтверждена метриками (например, рост drop_rate на 20% при падении трафика).
- **0.5–0.8** — вероятная причина, есть подтверждающие KPI, но возможны иные факторы.
- **0.2–0.5** — гипотеза, данных недостаточно для однозначного вывода.
- **0–0.2** — спекуляция, без численного подтверждения не формулировать как вывод.

Без численного подтверждения вывод о причине делать запрещено.

## Кодовый контур (аналитические скрипты)

Для сложных расчётов и графиков используй генерацию кода и запуск через `execute_analysis_script(scenario_id, script_content, timeout_sec)`.

1. **GENERATE_SCRIPT** — сформируй Python-скрипт, который:
   - читает данные из БД по переменной окружения `DB_PATH` (sqlite3) или используй уже выгруженные TSV в папке сценария;
   - пишет результаты только в `os.environ.get("OUTPUT_DIR", ".")`: таблицы в `results/`, графики в `plots/`;
   - использует только разрешённые библиотеки: pandas, numpy, matplotlib, seaborn, sqlite3, pathlib, os, json.
2. **RUN** — вызови `execute_analysis_script`. При успехе в ответе будут `log_path` и `result_paths`.
3. **VALIDATE** — проверь артефакты через `list_experiment_artifacts(scenario_id)`.
4. **DEBUG_LOOP** — при ошибке (success: False) по полю `error` (traceback) исправь скрипт и вызови `execute_analysis_script` снова. Не более 2–3 попыток; при повторяющейся ошибке зафиксируй в отчёте и перейди дальше.

Сценарий хранится в `ai_experiments/<scenario_id>/` (analysis.py, run.log, results/, plots/).

## Сценарий «низкий трафик БС» (end-to-end)

Выполняй по шагам; каждый шаг завершай STEP_RESULT с цифрами и confidence.

1. **Диапазон дат** — определи max_date по БД, задай baseline (например max_date−90 … max_date−15) и recent (max_date−14 … max_date).
2. **Отбор БС с минимальным трафиком** — агрегация по NE за recent, трафик = traffic_ps + traffic_cs (или только traffic_ps). Топ-N с наименьшей медианой/суммой. Пример SQL:
   `SELECT ne, SUM(traffic_ps) AS t_ps, SUM(traffic_cs) AS t_cs FROM network_stats WHERE dt BETWEEN ? AND ? GROUP BY ne ORDER BY t_ps ASC LIMIT 20`
3. **Сравнение baseline vs recent** — по каждой отобранной БС посчитать медианы (или средние) за baseline и за recent по трафику и по KPI (drop_rate, paging_succ, calls, rrc_conn, prb_util). Классифицировать: «всегда низкий» / «стал низкий» / «аномалия».
4. **RCA** — для «стал низкий» проверить причины по порядку (доступность → качество → спрос → нагрузка → сезонность), каждую подкреплять метриками и присвоить confidence.
5. **Таблицы и графики** — для проблемных БС сформировать: таблицу метрик (baseline vs recent), 2–4 графика динамики (трафик, ключевые KPI по датам). Использовать `execute_analysis_script`: скрипт читает из DB_PATH, пишет в OUTPUT_DIR/results/ и OUTPUT_DIR/plots/.
6. **FINAL_REPORT** — по шаблону (см. ниже): summary, список БС, RCA с confidence, рекомендации, пути к артефактам.

## Шаблон FINAL_REPORT

Итоговый отчёт по анализу низкого трафика оформляй в таком виде и сохраняй в `ai_experiments/<scenario_id>/report.md`.

```markdown
# FINAL_REPORT: Низкий трафик БС

## Executive summary
Кратко: сколько БС в выборке, сколько «всегда низкий» / «стал низкий», главная причина по сети (1–2 предложения).

## Топ проблемных БС
| NE | Статус | Трафик recent | Трафик baseline | Изменение % |
|----|--------|---------------|-----------------|-------------|
| …  | …      | …             | …               | …           |

## RCA по БС
Для каждой проблемной БС (кратко):
- **NE**: код
- **Вероятная причина**: текст
- **Confidence**: 0–1
- **Подтверждающие KPI**: метрики и значения
- **Рекомендации**: что проверить/сделать

## Рекомендации (приоритет)
1. …
2. …

## Артефакты
- Таблицы: пути к results/*.csv
- Графики: пути к plots/*.png
- Лог запуска: ai_experiments/<scenario_id>/run.log
```

## Генерация тестовых данных

Тестовые данные создаются скриптом `tools/fake_network_stats.py` (команды `create-schema`, `generate`). Реальная загрузка статистики в проект не описана в этом навыке — БД считается уже существующей при запросах агента.
